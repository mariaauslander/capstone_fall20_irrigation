{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yp4TwCNvfgFH"
   },
   "source": [
    "# SimCLR\n",
    "### Jade\n",
    "### Test different data augmentation techniques in SimCLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Pl5H81Lf2j7"
   },
   "source": [
    "### Part 0: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5UYuDqepHzrg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "from tensorflow.keras.applications import ResNet50, ResNet101V2, Xception, InceptionV3\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#from utils import *\n",
    "#import helpers\n",
    "#import losses\n",
    "import argparse\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ubYzTfxf8HA"
   },
   "source": [
    "### Part 1: Set path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "YtpGUv1uKR7l",
    "outputId": "b2ee96a2-af7b-4905-a245-b9b19bb66f9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WtYPJfwaKjgs"
   },
   "outputs": [],
   "source": [
    "BASE_PATH = '/content/gdrive/My Drive/BigEarthNet/'\n",
    "OUTPUT_PATH = os.path.join(BASE_PATH, 'data_augmentation')\n",
    "TFR_PATH = os.path.join(BASE_PATH, 'tfrecords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zV71z6qQgDBm"
   },
   "source": [
    "### Part 2: Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9lFC96cuH6gX"
   },
   "outputs": [],
   "source": [
    "# helper\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#from augmentation.gaussian_filter import GaussianBlur\n",
    "\n",
    "\n",
    "def get_negative_mask(batch_size):\n",
    "    # return a mask that removes the similarity score of equal/similar images.\n",
    "    # this function ensures that only distinct pair of images get their similarity scores\n",
    "    # passed as negative examples\n",
    "    negative_mask = np.ones((batch_size, 2 * batch_size), dtype=bool)\n",
    "    for i in range(batch_size):\n",
    "        negative_mask[i, i] = 0\n",
    "        negative_mask[i, i + batch_size] = 0\n",
    "    return tf.constant(negative_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lBk0rH5vILQh"
   },
   "outputs": [],
   "source": [
    "# losses\n",
    "import tensorflow as tf\n",
    "\n",
    "cosine_sim_1d = tf.keras.losses.CosineSimilarity(axis=1, reduction=tf.keras.losses.Reduction.NONE)\n",
    "cosine_sim_2d = tf.keras.losses.CosineSimilarity(axis=2, reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "\n",
    "def _cosine_simililarity_dim1(x, y):\n",
    "    v = cosine_sim_1d(x, y)\n",
    "    return v\n",
    "\n",
    "\n",
    "def _cosine_simililarity_dim2(x, y):\n",
    "    # x shape: (N, 1, C)\n",
    "    # y shape: (1, 2N, C)\n",
    "    # v shape: (N, 2N)\n",
    "    v = cosine_sim_2d(tf.expand_dims(x, 1), tf.expand_dims(y, 0))\n",
    "    return v\n",
    "\n",
    "\n",
    "def _dot_simililarity_dim1(x, y):\n",
    "    # x shape: (N, 1, C)\n",
    "    # y shape: (N, C, 1)\n",
    "    # v shape: (N, 1, 1)\n",
    "    v = tf.matmul(tf.expand_dims(x, 1), tf.expand_dims(y, 2))\n",
    "    return v\n",
    "\n",
    "\n",
    "def _dot_simililarity_dim2(x, y):\n",
    "    v = tf.tensordot(tf.expand_dims(x, 1), tf.expand_dims(tf.transpose(y), 0), axes=2)\n",
    "    # x shape: (N, 1, C)\n",
    "    # y shape: (1, C, 2N)\n",
    "    # v shape: (N, 2N)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zHmEae_uIUM2"
   },
   "outputs": [],
   "source": [
    "#util\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n",
    "def read_tfrecord(example):\n",
    "    BAND_STATS = {\n",
    "        'mean': {\n",
    "            'B01': 340.76769064,\n",
    "            'B02': 429.9430203,\n",
    "            'B03': 614.21682446,\n",
    "            'B04': 590.23569706,\n",
    "            'B05': 950.68368468,\n",
    "            'B06': 1792.46290469,\n",
    "            'B07': 2075.46795189,\n",
    "            'B08': 2218.94553375,\n",
    "            'B8A': 2266.46036911,\n",
    "            'B09': 2246.0605464,\n",
    "            'B11': 1594.42694882,\n",
    "            'B12': 1009.32729131\n",
    "        },\n",
    "        'std': {\n",
    "            'B01': 554.81258967,\n",
    "            'B02': 572.41639287,\n",
    "            'B03': 582.87945694,\n",
    "            'B04': 675.88746967,\n",
    "            'B05': 729.89827633,\n",
    "            'B06': 1096.01480586,\n",
    "            'B07': 1273.45393088,\n",
    "            'B08': 1365.45589904,\n",
    "            'B8A': 1356.13789355,\n",
    "            'B09': 1302.3292881,\n",
    "            'B11': 1079.19066363,\n",
    "            'B12': 818.86747235\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Use this one-liner to standardize each feature prior to reshaping.\n",
    "    def standardize_feature(data, band_name):\n",
    "        return ((tf.dtypes.cast(data, tf.float32) - BAND_STATS['mean'][band_name]) / BAND_STATS['std'][band_name])\n",
    "\n",
    "    # decode the TFRecord\n",
    "    # The parse single example methods takes an example (from a tfrecords file),\n",
    "    # and a dictionary that explains the data format of each feature.\n",
    "    example = tf.io.parse_single_example(example, {\n",
    "        'B01': tf.io.FixedLenFeature([20 * 20], tf.int64),\n",
    "        'B02': tf.io.FixedLenFeature([120 * 120], tf.int64),\n",
    "        'B03': tf.io.FixedLenFeature([120 * 120], tf.int64),\n",
    "        'B04': tf.io.FixedLenFeature([120 * 120], tf.int64),\n",
    "        'B05': tf.io.FixedLenFeature([60 * 60], tf.int64),\n",
    "        'B06': tf.io.FixedLenFeature([60 * 60], tf.int64),\n",
    "        'B07': tf.io.FixedLenFeature([60 * 60], tf.int64),\n",
    "        'B08': tf.io.FixedLenFeature([120 * 120], tf.int64),\n",
    "        'B8A': tf.io.FixedLenFeature([60 * 60], tf.int64),\n",
    "        'B09': tf.io.FixedLenFeature([20 * 20], tf.int64),\n",
    "        'B11': tf.io.FixedLenFeature([60 * 60], tf.int64),\n",
    "        'B12': tf.io.FixedLenFeature([60 * 60], tf.int64),\n",
    "        'patch_name': tf.io.VarLenFeature(dtype=tf.string),\n",
    "        'original_labels': tf.io.VarLenFeature(dtype=tf.string),\n",
    "        'original_labels_multi_hot': tf.io.FixedLenFeature([43], tf.int64)\n",
    "    })\n",
    "\n",
    "    example['binary_label'] = example['original_labels_multi_hot'][tf.constant(12)]\n",
    "\n",
    "    # After parsing our data into a tensor, let's standardize and reshape.\n",
    "    reshaped_example = {\n",
    "        'B01': tf.reshape(standardize_feature(example['B01'], 'B01'), [20, 20]),\n",
    "        'B02': tf.reshape(standardize_feature(example['B02'], 'B02'), [120, 120]),\n",
    "        'B03': tf.reshape(standardize_feature(example['B03'], 'B03'), [120, 120]),\n",
    "        'B04': tf.reshape(standardize_feature(example['B04'], 'B04'), [120, 120]),\n",
    "        'B05': tf.reshape(standardize_feature(example['B05'], 'B05'), [60, 60]),\n",
    "        'B06': tf.reshape(standardize_feature(example['B06'], 'B06'), [60, 60]),\n",
    "        'B07': tf.reshape(standardize_feature(example['B07'], 'B07'), [60, 60]),\n",
    "        'B08': tf.reshape(standardize_feature(example['B08'], 'B08'), [120, 120]),\n",
    "        'B8A': tf.reshape(standardize_feature(example['B8A'], 'B8A'), [60, 60]),\n",
    "        'B09': tf.reshape(standardize_feature(example['B09'], 'B09'), [20, 20]),\n",
    "        'B11': tf.reshape(standardize_feature(example['B11'], 'B11'), [60, 60]),\n",
    "        'B12': tf.reshape(standardize_feature(example['B12'], 'B12'), [60, 60]),\n",
    "        'patch_name': example['patch_name'],\n",
    "        'original_labels': example['original_labels'],\n",
    "        'original_labels_multi_hot': example['original_labels_multi_hot'],\n",
    "        'binary_labels': example['binary_label']\n",
    "    }\n",
    "\n",
    "    # Next sort the layers by resolution\n",
    "    bands_10m = tf.stack([reshaped_example['B04'],\n",
    "                          reshaped_example['B03'],\n",
    "                          reshaped_example['B02'],\n",
    "                          reshaped_example['B08']], axis=2)\n",
    "\n",
    "    bands_20m = tf.stack([reshaped_example['B05'],\n",
    "                          reshaped_example['B06'],\n",
    "                          reshaped_example['B07'],\n",
    "                          reshaped_example['B8A'],\n",
    "                          reshaped_example['B11'],\n",
    "                          reshaped_example['B12']], axis=2)\n",
    "\n",
    "    # Finally resize the 20m data and stack the bands together.\n",
    "    img = tf.concat([bands_10m, tf.image.resize(bands_20m, [120, 120], method='bicubic')], axis=2)\n",
    "    \n",
    "    multi_hot_label = reshaped_example['original_labels_multi_hot']\n",
    "    binary_label = reshaped_example['binary_labels']\n",
    "    \n",
    "    # Can update this to return the multilabel if doing multi-class classification\n",
    "    return img, binary_label\n",
    "  \n",
    "  \n",
    "def get_batched_dataset(filenames, batch_size, augment=False):\n",
    "    option_no_order = tf.data.Options()\n",
    "    option_no_order.experimental_deterministic = False\n",
    "\n",
    "    dataset = tf.data.Dataset.list_files(filenames, shuffle=True)\n",
    "    print(f'Filenames: {filenames}')\n",
    "    dataset = dataset.with_options(option_no_order)\n",
    "    dataset = dataset.interleave(tf.data.TFRecordDataset, cycle_length=2, num_parallel_calls=1)\n",
    "    dataset = dataset.shuffle(buffer_size=2048)\n",
    "    #.repeat()\n",
    "    \n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=10)\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)  # drop_remainder will be needed on TPU\n",
    "    dataset = dataset.prefetch(5)  #\n",
    "\n",
    "    return dataset\n",
    "\n",
    "class TimeHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "\n",
    "class Augment():\n",
    "  def augfunc(self, sample):        \n",
    "    # Randomly apply transformation (color distortions) with probability p.\n",
    "    sample = self._random_apply(self._color_jitter, sample, p=0.8)\n",
    "    sample = self._random_apply(self._color_drop, sample, p=0.2)\n",
    "    sample = self._random_apply(self._blur, sample, p=0.5)\n",
    "\n",
    "    return sample\n",
    "\n",
    "  def _color_jitter(self,  x, s=1):\n",
    "      # one can also shuffle the order of following augmentations\n",
    "      # each time they are applied.\n",
    "      x = tf.image.random_brightness(x, max_delta=0.8*s)\n",
    "      x = tf.image.random_contrast(x, lower=1-0.8*s, upper=1+0.8*s)\n",
    "      dx = tf.image.random_saturation(x[:,:,:3], lower=1-0.8*s, upper=1+0.8*s)\n",
    "      dx = tf.image.random_hue(dx, max_delta=0.2*s)\n",
    "      x = tf.concat([dx, x[:,:,3:]],axis=2)\n",
    "      x = tf.clip_by_value(x, 0, 1)\n",
    "      return x\n",
    "\n",
    "  def _color_drop(self, x):\n",
    "      dx = tf.image.rgb_to_grayscale(x[:,:,:3])\n",
    "      dx = tf.tile(dx, [1, 1, 3])\n",
    "      x = tf.concat([dx, x[:,:,3:]],axis=2)\n",
    "      return x\n",
    "\n",
    "  def _blur(self, x):\n",
    "      # SimClr implementation is applied at 10% of image size with a random sigma\n",
    "      p = np.random.uniform(0.1,2)\n",
    "      if type(x) == np.ndarray:\n",
    "          return (cv2.GaussianBlur(x,(5,5),p))\n",
    "      return (cv2.GaussianBlur(x.numpy(),(5,5),p))\n",
    "\n",
    "  def _random_apply(self, func, x, p):\n",
    "      return tf.cond(\n",
    "        tf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
    "                tf.cast(p, tf.float32)),\n",
    "        lambda: func(x),\n",
    "        lambda: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "7wym4vcYIr8P"
   },
   "outputs": [],
   "source": [
    "def get_training_dataset(training_filenames, batch_size):\n",
    "  return get_batched_dataset(training_filenames, batch_size)\n",
    "\n",
    "\n",
    "def build_simclr_model(imported_model, hidden_1, hidden_2, hidden_3):\n",
    "  \n",
    "  base_model = imported_model(include_top=False, weights=None, input_shape=[120,120, 10])\n",
    "  base_model.trainable = True\n",
    "  \n",
    "  inputs = Input((120,120, 10))\n",
    "  \n",
    "  h = base_model(inputs, training=True)\n",
    "  h = GlobalAveragePooling2D()(h)\n",
    "  \n",
    "  projection_1 = Dense(hidden_1)(h)\n",
    "  projection_1 = Activation(\"relu\")(projection_1)\n",
    "  projection_2 = Dense(hidden_2)(projection_1)\n",
    "  projection_2 = Activation(\"relu\")(projection_2)\n",
    "  projection_3 = Dense(hidden_3)(projection_2)\n",
    "\n",
    "  simclr_model = tf.keras.models.Model(inputs, projection_3)\n",
    "  \n",
    "  return simclr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "uWbbZmJfIvVq"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(xis, xjs, model, optimizer, criterion, temperature, batch_size):\n",
    "    # Mask to remove positive examples from the batch of negative samples\n",
    "    negative_mask = get_negative_mask(batch_size)\n",
    "  \n",
    "    with tf.GradientTape() as tape:\n",
    "        zis = model(xis)\n",
    "        zjs = model(xjs)\n",
    "\n",
    "        # normalize projection feature vectors\n",
    "        zis = tf.math.l2_normalize(zis, axis=1)\n",
    "        zjs = tf.math.l2_normalize(zjs, axis=1)\n",
    "\n",
    "        l_pos = _dot_simililarity_dim1(zis, zjs)\n",
    "        l_pos = tf.reshape(l_pos, (batch_size, 1))\n",
    "        l_pos /= temperature\n",
    "\n",
    "        negatives = tf.concat([zjs, zis], axis=0)\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        for positives in [zis, zjs]:\n",
    "            l_neg = _dot_simililarity_dim2(positives, negatives)\n",
    "\n",
    "            labels = tf.zeros(batch_size, dtype=tf.int32)\n",
    "\n",
    "            l_neg = tf.boolean_mask(l_neg, negative_mask)\n",
    "            l_neg = tf.reshape(l_neg, (batch_size, -1))\n",
    "            l_neg /= temperature\n",
    "\n",
    "            logits = tf.concat([l_pos, l_neg], axis=1) \n",
    "            loss += criterion(y_pred=logits, y_true=labels)\n",
    "\n",
    "        loss = loss / (2 * batch_size)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "K96iqFSBIyI9"
   },
   "outputs": [],
   "source": [
    "def run_model(name, BATCH_SIZE, epochs, architecture, temperature):\n",
    "    \n",
    "    print(50 * \"*\")\n",
    "    print(f\"Running model: SimCLR {name}\")\n",
    "    print(50 * \"=\")\n",
    "    print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "    print(50 * \"=\")\n",
    "    print(f'Using Model Architecture: {architecture}')\n",
    "    \n",
    "    training_filenames = f'{TFR_PATH}/train-part-0.tfrecord'\n",
    "    training_data = get_training_dataset(training_filenames, BATCH_SIZE)\n",
    "\n",
    "#     len_train_records = 9942*5\n",
    "#     steps_per_epoch = len_train_records // BATCH_SIZE\n",
    "    \n",
    "    criterion = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, \n",
    "                                                          reduction=tf.keras.losses.Reduction.SUM)\n",
    "    decay_steps = 1000\n",
    "    lr_decayed_fn = tf.keras.experimental.CosineDecay(\n",
    "        initial_learning_rate=0.1, decay_steps=decay_steps)\n",
    "    optimizer = tf.keras.optimizers.SGD(lr_decayed_fn)\n",
    "\n",
    "    simclr_2 = build_simclr_model(architecture,1024, 512, 128)\n",
    "    simclr_2.summary()\n",
    "\n",
    "    \n",
    "    epoch_wise_loss = []\n",
    "    \n",
    "    time_callback = TimeHistory()\n",
    "    augment = Augment()\n",
    "    \n",
    "    ROTATION = 180\n",
    "    SHIFT = 0.10\n",
    "    FLIP = True\n",
    "    ZOOM = 0.20\n",
    "    JITTER = True\n",
    "    BLUR = True\n",
    "    \n",
    "    datagen = image.ImageDataGenerator(\n",
    "            rotation_range=ROTATION,\n",
    "            width_shift_range=SHIFT,\n",
    "            height_shift_range=SHIFT,\n",
    "            horizontal_flip=FLIP,\n",
    "            vertical_flip=FLIP,\n",
    "            zoom_range=ZOOM,\n",
    "            preprocessing_function= augment.augfunc)\n",
    "    \n",
    "    min_loss = 1e6\n",
    "    min_loss_epoch = 0\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "      step_wise_loss = []\n",
    "      for image_batch in tqdm(training_data):\n",
    "        a = datagen.flow(image_batch, batch_size=BATCH_SIZE, shuffle=False)\n",
    "        b = datagen.flow(image_batch, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        loss = train_step(a[0][0], b[0][0], simclr_2, optimizer, criterion, temperature=0.1, batch_size=BATCH_SIZE)\n",
    "        step_wise_loss.append(loss)\n",
    "\n",
    "      epoch_wise_loss.append(np.mean(step_wise_loss))\n",
    "      # Print the loss after every epoch\n",
    "      print(f\"****epoch: {epoch + 1} loss: {epoch_wise_loss[-1]:.3f}****\\n\")\n",
    "        \n",
    "      # Save best weights\n",
    "      if epoch_wise_loss[-1] < min_loss:\n",
    "        # Save the final model with weights\n",
    "        simclr_2.save(f'{OUTPUT_PATH}/{name}.h5')\n",
    "        min_loss_epoch = epoch+1\n",
    "  \n",
    "    # Store the epochwise loss and model metadata to dataframe\n",
    "    df = pd.DataFrame(epoch_wise_loss)\n",
    "    df['temperature'] = temperature\n",
    "    df['batch_size'] = BATCH_SIZE\n",
    "    df['epochs'] = epochs\n",
    "    df['h1'] = 1024\n",
    "    df['h2'] = 512\n",
    "    df['output_dim'] = 128\n",
    "    df['rotation'] = ROTATION\n",
    "    df['shift'] = ROTATION\n",
    "    df['flip'] = ROTATION\n",
    "    df['zoom'] = ROTATION\n",
    "    df['jitter'] = ROTATION\n",
    "    df['blur'] = ROTATION\n",
    "    df['best_epoch'] = min_loss_epoch\n",
    "  \n",
    "    df.to_pickle(f'{OUTPUT_PATH}/{name}.pkl')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyh8joF0gRl6"
   },
   "source": [
    "### Part 3: Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kTp1QfeEI1fO",
    "outputId": "477f9ab5-ac77-49a1-8ca8-601e6f76723c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Running model: SimCLR simclr1\n",
      "==================================================\n",
      "Batch Size: 32\n",
      "==================================================\n",
      "Using Model Architecture: <function ResNet50 at 0x7f6c179ba730>\n",
      "Filenames: /content/gdrive/My Drive/BigEarthNet/tfrecords/train-part-0.tfrecord\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/applications/imagenet_utils.py:333: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 10 input channels.\n",
      "  str(input_shape[-1]) + ' input channels.')\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 120, 120, 10)]    0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 4, 4, 2048)        23609664  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "=================================================================\n",
      "Total params: 26,298,304\n",
      "Trainable params: 26,245,184\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/numpy_array_iterator.py:136: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (32, 120, 120, 10) (10 channels).\n",
      "  str(self.x.shape[channels_axis]) + ' channels).')\n",
      "\n",
      "1it [00:24, 24.74s/it]\u001b[A\n",
      "2it [00:40, 22.03s/it]\u001b[A\n",
      "3it [00:56, 20.13s/it]\u001b[A\n",
      "4it [01:11, 18.81s/it]\u001b[A\n",
      "5it [01:27, 17.87s/it]\u001b[A\n",
      "6it [01:43, 17.20s/it]\u001b[A\n",
      "7it [01:58, 16.79s/it]\u001b[A\n",
      "8it [02:14, 16.44s/it]\u001b[A\n",
      "9it [02:30, 16.21s/it]\u001b[A\n",
      "10it [02:45, 16.03s/it]\u001b[A\n",
      "11it [03:01, 15.92s/it]\u001b[A\n",
      "12it [03:17, 15.81s/it]\u001b[A\n",
      "13it [03:32, 15.76s/it]\u001b[A\n",
      "14it [03:48, 15.69s/it]\u001b[A\n",
      "15it [04:04, 15.75s/it]\u001b[A\n",
      "16it [04:19, 15.68s/it]\u001b[A\n",
      "17it [04:35, 15.70s/it]\u001b[A\n",
      "18it [04:51, 15.66s/it]\u001b[A\n",
      "19it [05:06, 15.66s/it]\u001b[A\n",
      "20it [05:25, 16.52s/it]\u001b[A\n",
      "21it [05:40, 16.27s/it]\u001b[A\n",
      "22it [05:56, 16.10s/it]\u001b[A\n",
      "23it [06:12, 16.02s/it]\u001b[A\n",
      "24it [06:28, 15.92s/it]\u001b[A\n",
      "25it [06:43, 15.82s/it]\u001b[A\n",
      "26it [06:59, 15.78s/it]\u001b[A\n",
      "27it [07:14, 15.69s/it]\u001b[A\n",
      "28it [07:30, 15.64s/it]\u001b[A\n",
      "29it [07:45, 15.59s/it]\u001b[A\n",
      "30it [08:01, 15.61s/it]\u001b[A\n",
      "31it [08:17, 15.59s/it]\u001b[A\n",
      "32it [08:32, 15.59s/it]\u001b[A\n",
      "33it [08:48, 15.57s/it]\u001b[A\n",
      "34it [09:03, 15.59s/it]\u001b[A\n",
      "35it [09:19, 15.59s/it]\u001b[A\n",
      "36it [09:34, 15.59s/it]\u001b[A\n",
      "37it [09:50, 15.58s/it]\u001b[A\n",
      "38it [10:06, 15.61s/it]\u001b[A\n",
      "39it [10:21, 15.64s/it]\u001b[A\n",
      "40it [10:37, 15.70s/it]\u001b[A\n",
      "41it [10:53, 15.81s/it]\u001b[A\n",
      "42it [11:09, 15.80s/it]\u001b[A\n",
      "43it [11:25, 15.84s/it]\u001b[A\n",
      "44it [11:41, 15.80s/it]\u001b[A\n",
      "45it [11:57, 15.80s/it]\u001b[A\n",
      "46it [12:12, 15.82s/it]\u001b[A\n",
      "47it [12:28, 15.83s/it]\u001b[A\n",
      "48it [12:44, 15.78s/it]\u001b[A\n",
      "49it [13:00, 15.77s/it]\u001b[A\n",
      "50it [13:15, 15.74s/it]\u001b[A\n",
      "51it [13:31, 15.77s/it]\u001b[A\n",
      "52it [13:47, 15.75s/it]\u001b[A\n",
      "53it [14:03, 15.80s/it]\u001b[A\n",
      "54it [14:19, 15.79s/it]\u001b[A\n",
      "55it [14:34, 15.76s/it]\u001b[A\n",
      "56it [14:50, 15.75s/it]\u001b[A\n",
      "57it [15:06, 15.73s/it]\u001b[A\n",
      "58it [15:21, 15.67s/it]\u001b[A\n",
      "59it [15:40, 16.64s/it]\u001b[A\n",
      "60it [15:56, 16.35s/it]\u001b[A\n",
      "61it [16:11, 16.15s/it]\u001b[A\n",
      "62it [16:27, 16.01s/it]\u001b[A\n",
      "63it [16:43, 15.95s/it]\u001b[A\n",
      "64it [16:59, 15.89s/it]\u001b[A\n",
      "65it [17:14, 15.78s/it]\u001b[A\n",
      "66it [17:30, 15.73s/it]\u001b[A\n",
      "67it [17:45, 15.70s/it]\u001b[A\n",
      "68it [18:01, 15.71s/it]\u001b[A\n",
      "69it [18:17, 15.67s/it]\u001b[A\n",
      "70it [18:32, 15.63s/it]\u001b[A\n",
      "71it [18:48, 15.62s/it]\u001b[A\n",
      "72it [19:04, 15.65s/it]\u001b[A\n",
      "73it [19:19, 15.67s/it]\u001b[A\n",
      "74it [19:35, 15.69s/it]\u001b[A\n",
      "75it [19:51, 15.70s/it]\u001b[A\n",
      "76it [20:07, 15.74s/it]\u001b[A\n",
      "77it [20:22, 15.73s/it]\u001b[A\n",
      "78it [20:38, 15.71s/it]\u001b[A\n",
      "79it [20:54, 15.74s/it]\u001b[A\n",
      "80it [21:09, 15.67s/it]\u001b[A\n",
      "81it [21:25, 15.62s/it]\u001b[A\n",
      "82it [21:40, 15.62s/it]\u001b[A\n",
      "83it [21:56, 15.67s/it]\u001b[A\n",
      "84it [22:12, 15.63s/it]\u001b[A\n",
      "85it [22:27, 15.64s/it]\u001b[A\n",
      "86it [22:43, 15.63s/it]\u001b[A\n",
      "87it [22:59, 15.70s/it]\u001b[A\n",
      "88it [23:15, 15.69s/it]\u001b[A\n",
      "89it [23:30, 15.70s/it]\u001b[A\n",
      "90it [23:46, 15.68s/it]\u001b[A\n",
      "91it [24:02, 15.74s/it]\u001b[A\n",
      "92it [24:18, 15.75s/it]\u001b[A\n",
      "93it [24:33, 15.77s/it]\u001b[A\n",
      "94it [24:49, 15.74s/it]\u001b[A\n",
      "95it [25:05, 15.75s/it]\u001b[A\n",
      "96it [25:20, 15.71s/it]\u001b[A\n",
      "97it [25:36, 15.71s/it]\u001b[A\n",
      "98it [25:54, 16.45s/it]\u001b[A\n",
      "99it [26:10, 16.24s/it]\u001b[A\n",
      "100it [26:26, 16.09s/it]\u001b[A\n",
      "101it [26:42, 15.97s/it]\u001b[A\n",
      "102it [26:58, 16.06s/it]\u001b[A\n",
      "103it [27:14, 15.98s/it]\u001b[A\n",
      "104it [27:29, 15.91s/it]\u001b[A\n",
      "105it [27:45, 15.89s/it]\u001b[A\n",
      "106it [28:01, 15.88s/it]\u001b[A\n",
      "107it [28:17, 15.79s/it]\u001b[A\n",
      "108it [28:32, 15.76s/it]\u001b[A\n",
      "109it [28:48, 15.73s/it]\u001b[A\n",
      "110it [29:04, 15.73s/it]\u001b[A\n",
      "111it [29:19, 15.70s/it]\u001b[A\n",
      "112it [29:35, 15.72s/it]\u001b[A\n",
      "113it [29:51, 15.70s/it]\u001b[A\n",
      "114it [30:06, 15.70s/it]\u001b[A\n",
      "115it [30:22, 15.68s/it]\u001b[A\n",
      "116it [30:38, 15.62s/it]\u001b[A\n",
      "117it [30:53, 15.63s/it]\u001b[A\n",
      "118it [31:09, 15.62s/it]\u001b[A\n",
      "119it [31:24, 15.63s/it]\u001b[A\n",
      "120it [31:40, 15.62s/it]\u001b[A\n",
      "121it [31:56, 15.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****epoch: 1 loss: 3.574****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [31:57<2:07:51, 1917.87s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:17, 17.53s/it]\u001b[A\n",
      "2it [00:33, 16.98s/it]\u001b[A\n",
      "3it [00:48, 16.58s/it]\u001b[A\n",
      "4it [01:04, 16.38s/it]\u001b[A\n",
      "5it [01:20, 16.18s/it]\u001b[A\n",
      "6it [01:36, 16.03s/it]\u001b[A\n",
      "7it [01:51, 15.94s/it]\u001b[A\n",
      "8it [02:07, 15.91s/it]\u001b[A\n",
      "9it [02:23, 15.82s/it]\u001b[A\n",
      "10it [02:39, 15.79s/it]\u001b[A\n",
      "11it [02:55, 15.84s/it]\u001b[A\n",
      "12it [03:10, 15.86s/it]\u001b[A\n",
      "13it [03:26, 15.84s/it]\u001b[A\n",
      "14it [03:42, 15.82s/it]\u001b[A\n",
      "15it [04:00, 16.62s/it]\u001b[A\n",
      "16it [04:16, 16.35s/it]\u001b[A\n",
      "17it [04:32, 16.20s/it]\u001b[A\n",
      "18it [04:48, 16.14s/it]\u001b[A\n",
      "19it [05:04, 16.12s/it]\u001b[A\n",
      "20it [05:20, 16.11s/it]\u001b[A\n",
      "21it [05:36, 16.06s/it]\u001b[A\n",
      "22it [05:52, 16.01s/it]\u001b[A\n",
      "23it [06:08, 16.02s/it]\u001b[A\n",
      "24it [06:24, 15.99s/it]\u001b[A\n",
      "25it [06:40, 15.93s/it]\u001b[A\n",
      "26it [06:56, 15.89s/it]\u001b[A\n",
      "27it [07:11, 15.83s/it]\u001b[A\n",
      "28it [07:27, 15.80s/it]\u001b[A\n",
      "29it [07:43, 15.82s/it]\u001b[A\n",
      "30it [07:59, 15.84s/it]\u001b[A\n",
      "31it [08:15, 15.82s/it]\u001b[A\n",
      "32it [08:30, 15.82s/it]\u001b[A\n",
      "33it [08:46, 15.75s/it]\u001b[A\n",
      "34it [09:02, 15.71s/it]\u001b[A\n",
      "35it [09:17, 15.65s/it]\u001b[A\n",
      "36it [09:33, 15.67s/it]\u001b[A\n",
      "37it [09:48, 15.65s/it]\u001b[A\n",
      "38it [10:04, 15.69s/it]\u001b[A\n",
      "39it [10:20, 15.70s/it]\u001b[A\n",
      "40it [10:36, 15.78s/it]\u001b[A\n",
      "41it [10:52, 15.85s/it]\u001b[A\n",
      "42it [11:09, 16.10s/it]\u001b[A\n",
      "43it [11:25, 16.08s/it]\u001b[A\n",
      "44it [11:41, 16.06s/it]\u001b[A\n",
      "45it [11:57, 16.03s/it]\u001b[A\n",
      "46it [12:13, 16.02s/it]\u001b[A\n",
      "47it [12:28, 15.97s/it]\u001b[A\n",
      "48it [12:44, 15.91s/it]\u001b[A\n",
      "49it [13:00, 15.93s/it]\u001b[A\n",
      "50it [13:16, 15.93s/it]\u001b[A\n",
      "51it [13:32, 15.90s/it]\u001b[A\n",
      "52it [13:48, 15.83s/it]\u001b[A\n",
      "53it [14:06, 16.55s/it]\u001b[A\n",
      "54it [14:22, 16.36s/it]\u001b[A\n",
      "55it [14:38, 16.20s/it]\u001b[A\n",
      "56it [14:53, 16.07s/it]\u001b[A\n",
      "57it [15:09, 15.97s/it]\u001b[A\n",
      "58it [15:25, 15.94s/it]\u001b[A\n",
      "59it [15:41, 15.89s/it]\u001b[A\n",
      "60it [15:57, 15.88s/it]\u001b[A\n",
      "61it [16:12, 15.86s/it]\u001b[A\n",
      "62it [16:28, 15.87s/it]\u001b[A\n",
      "63it [16:44, 15.91s/it]\u001b[A\n",
      "64it [17:00, 15.94s/it]\u001b[A\n",
      "65it [17:16, 15.86s/it]\u001b[A\n",
      "66it [17:32, 15.86s/it]\u001b[A\n",
      "67it [17:48, 15.86s/it]\u001b[A\n",
      "68it [18:04, 15.92s/it]\u001b[A\n",
      "69it [18:20, 15.93s/it]\u001b[A\n",
      "70it [18:36, 15.95s/it]\u001b[A\n",
      "71it [18:52, 15.94s/it]\u001b[A\n",
      "72it [19:08, 15.96s/it]\u001b[A\n",
      "73it [19:24, 15.93s/it]\u001b[A\n",
      "74it [19:39, 15.93s/it]\u001b[A\n",
      "75it [19:55, 15.93s/it]\u001b[A\n",
      "76it [20:11, 15.89s/it]\u001b[A\n",
      "77it [20:27, 15.86s/it]\u001b[A\n",
      "78it [20:43, 15.82s/it]\u001b[A\n",
      "79it [20:59, 16.00s/it]\u001b[A\n",
      "80it [21:15, 15.88s/it]\u001b[A\n",
      "81it [21:30, 15.80s/it]\u001b[A\n",
      "82it [21:46, 15.74s/it]\u001b[A\n",
      "83it [22:02, 15.72s/it]\u001b[A\n",
      "84it [22:17, 15.70s/it]\u001b[A\n",
      "85it [22:33, 15.70s/it]\u001b[A\n",
      "86it [22:49, 15.77s/it]\u001b[A\n",
      "87it [23:05, 15.88s/it]\u001b[A\n",
      "88it [23:21, 15.86s/it]\u001b[A\n",
      "89it [23:37, 15.86s/it]\u001b[A\n",
      "90it [23:53, 15.85s/it]\u001b[A\n",
      "91it [24:08, 15.84s/it]\u001b[A\n",
      "92it [24:26, 16.50s/it]\u001b[A\n",
      "93it [24:42, 16.26s/it]\u001b[A\n",
      "94it [24:58, 16.11s/it]\u001b[A\n",
      "95it [25:14, 16.01s/it]\u001b[A\n",
      "96it [25:29, 15.97s/it]\u001b[A\n",
      "97it [25:45, 15.96s/it]\u001b[A\n",
      "98it [26:01, 15.98s/it]\u001b[A\n",
      "99it [26:17, 15.98s/it]\u001b[A\n",
      "100it [26:34, 16.05s/it]\u001b[A\n",
      "101it [26:49, 15.96s/it]\u001b[A\n",
      "102it [27:05, 15.95s/it]\u001b[A\n",
      "103it [27:21, 15.89s/it]\u001b[A\n",
      "104it [27:37, 15.88s/it]\u001b[A\n",
      "105it [27:53, 15.85s/it]\u001b[A\n",
      "106it [28:08, 15.82s/it]\u001b[A\n",
      "107it [28:24, 15.83s/it]\u001b[A\n",
      "108it [28:40, 15.76s/it]\u001b[A\n",
      "109it [28:56, 15.79s/it]\u001b[A\n",
      "110it [29:11, 15.76s/it]\u001b[A\n",
      "111it [29:27, 15.72s/it]\u001b[A\n",
      "112it [29:43, 15.68s/it]\u001b[A\n",
      "113it [29:59, 15.72s/it]\u001b[A\n",
      "114it [30:14, 15.72s/it]\u001b[A\n",
      "115it [30:30, 15.70s/it]\u001b[A\n",
      "116it [30:45, 15.65s/it]\u001b[A\n",
      "117it [31:01, 15.66s/it]\u001b[A\n",
      "118it [31:17, 15.69s/it]\u001b[A\n",
      "119it [31:33, 15.68s/it]\u001b[A\n",
      "120it [31:48, 15.66s/it]\u001b[A\n",
      "121it [32:04, 15.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****epoch: 2 loss: 3.098****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [1:04:03<1:36:00, 1920.25s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:17, 17.62s/it]\u001b[A\n",
      "2it [00:33, 17.03s/it]\u001b[A\n",
      "3it [00:49, 16.64s/it]\u001b[A\n",
      "4it [01:04, 16.34s/it]\u001b[A\n",
      "5it [01:20, 16.16s/it]\u001b[A\n",
      "6it [01:35, 15.98s/it]\u001b[A\n",
      "7it [01:51, 15.91s/it]\u001b[A\n",
      "8it [02:07, 15.85s/it]\u001b[A\n",
      "9it [02:25, 16.60s/it]\u001b[A\n",
      "10it [02:41, 16.37s/it]\u001b[A\n",
      "11it [02:57, 16.19s/it]\u001b[A\n",
      "12it [03:12, 16.00s/it]\u001b[A\n",
      "13it [03:28, 15.91s/it]\u001b[A\n",
      "14it [03:44, 15.83s/it]\u001b[A\n",
      "15it [03:59, 15.79s/it]\u001b[A\n",
      "16it [04:15, 15.74s/it]\u001b[A\n",
      "17it [04:31, 15.75s/it]\u001b[A\n",
      "18it [04:47, 15.75s/it]\u001b[A\n",
      "19it [05:02, 15.78s/it]\u001b[A\n",
      "20it [05:18, 15.76s/it]\u001b[A\n",
      "21it [05:34, 15.75s/it]\u001b[A\n",
      "22it [05:50, 15.76s/it]\u001b[A\n",
      "23it [06:05, 15.78s/it]\u001b[A\n",
      "24it [06:21, 15.79s/it]\u001b[A\n",
      "25it [06:37, 15.77s/it]\u001b[A\n",
      "26it [06:53, 15.75s/it]\u001b[A\n",
      "27it [07:08, 15.71s/it]\u001b[A\n",
      "28it [07:24, 15.74s/it]\u001b[A\n",
      "29it [07:40, 15.71s/it]\u001b[A\n",
      "30it [07:56, 15.72s/it]\u001b[A\n",
      "31it [08:11, 15.70s/it]\u001b[A\n",
      "32it [08:27, 15.69s/it]\u001b[A\n",
      "33it [08:42, 15.65s/it]\u001b[A\n",
      "34it [08:58, 15.72s/it]\u001b[A\n",
      "35it [09:14, 15.69s/it]\u001b[A\n",
      "36it [09:30, 15.77s/it]\u001b[A\n",
      "37it [09:46, 15.97s/it]\u001b[A\n",
      "38it [10:02, 15.94s/it]\u001b[A\n",
      "39it [10:18, 15.86s/it]\u001b[A\n",
      "40it [10:34, 15.96s/it]\u001b[A\n",
      "41it [10:50, 15.93s/it]\u001b[A\n",
      "42it [11:06, 15.94s/it]\u001b[A\n",
      "43it [11:22, 15.96s/it]\u001b[A\n",
      "44it [11:38, 15.95s/it]\u001b[A\n",
      "45it [11:54, 15.93s/it]\u001b[A\n",
      "46it [12:10, 15.91s/it]\u001b[A\n",
      "47it [12:26, 15.94s/it]\u001b[A\n",
      "48it [12:45, 16.85s/it]\u001b[A\n",
      "49it [13:00, 16.56s/it]\u001b[A\n",
      "50it [13:16, 16.30s/it]\u001b[A\n",
      "51it [13:32, 16.15s/it]\u001b[A\n",
      "52it [13:48, 16.01s/it]\u001b[A\n",
      "53it [14:03, 15.91s/it]\u001b[A\n",
      "54it [14:19, 15.85s/it]\u001b[A\n",
      "55it [14:35, 15.75s/it]\u001b[A\n",
      "56it [14:50, 15.80s/it]\u001b[A\n",
      "57it [15:06, 15.71s/it]\u001b[A\n",
      "58it [15:22, 15.68s/it]\u001b[A\n",
      "59it [15:37, 15.64s/it]\u001b[A\n",
      "60it [15:53, 15.64s/it]\u001b[A\n",
      "61it [16:08, 15.67s/it]\u001b[A\n",
      "62it [16:24, 15.68s/it]\u001b[A\n",
      "63it [16:40, 15.67s/it]\u001b[A\n",
      "64it [16:55, 15.66s/it]\u001b[A\n",
      "65it [17:11, 15.68s/it]\u001b[A\n",
      "66it [17:27, 15.65s/it]\u001b[A\n",
      "67it [17:42, 15.63s/it]\u001b[A\n",
      "68it [17:58, 15.70s/it]\u001b[A\n",
      "69it [18:14, 15.77s/it]\u001b[A\n",
      "70it [18:30, 15.83s/it]\u001b[A\n",
      "71it [18:46, 15.76s/it]\u001b[A\n",
      "72it [19:01, 15.74s/it]\u001b[A\n",
      "73it [19:17, 15.68s/it]\u001b[A\n",
      "74it [19:33, 15.66s/it]\u001b[A\n",
      "75it [19:48, 15.70s/it]\u001b[A\n",
      "76it [20:04, 15.73s/it]\u001b[A\n",
      "77it [20:20, 15.72s/it]\u001b[A\n",
      "78it [20:36, 15.71s/it]\u001b[A\n",
      "79it [20:51, 15.72s/it]\u001b[A\n",
      "80it [21:07, 15.68s/it]\u001b[A\n",
      "81it [21:23, 15.66s/it]\u001b[A\n",
      "82it [21:38, 15.63s/it]\u001b[A\n",
      "83it [21:54, 15.65s/it]\u001b[A\n",
      "84it [22:09, 15.66s/it]\u001b[A\n",
      "85it [22:25, 15.65s/it]\u001b[A\n",
      "86it [22:43, 16.31s/it]\u001b[A\n",
      "87it [22:59, 16.13s/it]\u001b[A\n",
      "88it [23:14, 15.96s/it]\u001b[A\n",
      "89it [23:30, 15.85s/it]\u001b[A\n",
      "90it [23:45, 15.76s/it]\u001b[A\n",
      "91it [24:01, 15.74s/it]\u001b[A\n",
      "92it [24:17, 15.70s/it]\u001b[A\n",
      "93it [24:32, 15.69s/it]\u001b[A\n",
      "94it [24:48, 15.73s/it]\u001b[A\n",
      "95it [25:04, 15.85s/it]\u001b[A\n",
      "96it [25:20, 15.84s/it]\u001b[A\n",
      "97it [25:36, 15.82s/it]\u001b[A\n",
      "98it [25:52, 15.80s/it]\u001b[A\n",
      "99it [26:07, 15.79s/it]\u001b[A\n",
      "100it [26:23, 15.79s/it]\u001b[A\n",
      "101it [26:39, 15.76s/it]\u001b[A\n",
      "102it [26:55, 15.82s/it]\u001b[A\n",
      "103it [27:11, 15.82s/it]\u001b[A\n",
      "104it [27:26, 15.81s/it]\u001b[A\n",
      "105it [27:42, 15.79s/it]\u001b[A\n",
      "106it [27:58, 15.79s/it]\u001b[A\n",
      "107it [28:14, 15.73s/it]\u001b[A\n",
      "108it [28:29, 15.68s/it]\u001b[A\n",
      "109it [28:45, 15.66s/it]\u001b[A\n",
      "110it [29:01, 15.69s/it]\u001b[A\n",
      "111it [29:16, 15.69s/it]\u001b[A\n",
      "112it [29:32, 15.68s/it]\u001b[A\n",
      "113it [29:48, 15.73s/it]\u001b[A\n",
      "114it [30:03, 15.73s/it]\u001b[A\n",
      "115it [30:19, 15.72s/it]\u001b[A\n",
      "116it [30:35, 15.71s/it]\u001b[A\n",
      "117it [30:51, 15.81s/it]\u001b[A\n",
      "118it [31:06, 15.72s/it]\u001b[A\n",
      "119it [31:22, 15.68s/it]\u001b[A\n",
      "120it [31:37, 15.64s/it]\u001b[A\n",
      "121it [31:53, 15.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****epoch: 3 loss: 2.886****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [1:35:58<1:03:57, 1918.71s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:17, 17.28s/it]\u001b[A\n",
      "2it [00:32, 16.79s/it]\u001b[A\n",
      "3it [00:48, 16.41s/it]\u001b[A\n",
      "4it [01:06, 17.00s/it]\u001b[A\n",
      "5it [01:22, 16.58s/it]\u001b[A\n",
      "6it [01:38, 16.29s/it]\u001b[A\n",
      "7it [01:53, 16.10s/it]\u001b[A\n",
      "8it [02:09, 15.95s/it]\u001b[A\n",
      "9it [02:24, 15.84s/it]\u001b[A\n",
      "10it [02:40, 15.73s/it]\u001b[A\n",
      "11it [02:56, 15.71s/it]\u001b[A\n",
      "12it [03:11, 15.69s/it]\u001b[A\n",
      "13it [03:27, 15.69s/it]\u001b[A\n",
      "14it [03:43, 15.69s/it]\u001b[A\n",
      "15it [03:58, 15.70s/it]\u001b[A\n",
      "16it [04:14, 15.68s/it]\u001b[A\n",
      "17it [04:30, 15.65s/it]\u001b[A\n",
      "18it [04:45, 15.65s/it]\u001b[A\n",
      "19it [05:01, 15.72s/it]\u001b[A\n",
      "20it [05:17, 15.71s/it]\u001b[A\n",
      "21it [05:32, 15.70s/it]\u001b[A\n",
      "22it [05:48, 15.69s/it]\u001b[A\n",
      "23it [06:04, 15.71s/it]\u001b[A\n",
      "24it [06:20, 15.74s/it]\u001b[A\n",
      "25it [06:35, 15.76s/it]\u001b[A\n",
      "26it [06:51, 15.74s/it]\u001b[A\n",
      "27it [07:07, 15.75s/it]\u001b[A\n",
      "28it [07:22, 15.67s/it]\u001b[A\n",
      "29it [07:38, 15.65s/it]\u001b[A\n",
      "30it [07:54, 15.64s/it]\u001b[A\n",
      "31it [08:09, 15.62s/it]\u001b[A\n",
      "32it [08:25, 15.73s/it]\u001b[A\n",
      "33it [08:41, 15.69s/it]\u001b[A\n",
      "34it [08:57, 15.74s/it]\u001b[A\n",
      "35it [09:12, 15.69s/it]\u001b[A\n",
      "36it [09:28, 15.66s/it]\u001b[A\n",
      "37it [09:43, 15.63s/it]\u001b[A\n",
      "38it [09:59, 15.64s/it]\u001b[A\n",
      "39it [10:15, 15.65s/it]\u001b[A\n",
      "40it [10:30, 15.67s/it]\u001b[A\n",
      "41it [10:46, 15.70s/it]\u001b[A\n",
      "42it [11:03, 16.13s/it]\u001b[A\n",
      "43it [11:20, 16.18s/it]\u001b[A\n",
      "44it [11:35, 16.02s/it]\u001b[A\n",
      "45it [11:51, 15.90s/it]\u001b[A\n",
      "46it [12:07, 15.86s/it]\u001b[A\n",
      "47it [12:22, 15.83s/it]\u001b[A\n",
      "48it [12:39, 15.95s/it]\u001b[A\n",
      "49it [12:55, 16.09s/it]\u001b[A\n",
      "50it [13:11, 16.18s/it]\u001b[A\n",
      "51it [13:28, 16.24s/it]\u001b[A\n",
      "52it [13:44, 16.31s/it]\u001b[A\n",
      "53it [14:01, 16.32s/it]\u001b[A\n",
      "54it [14:16, 16.13s/it]\u001b[A\n",
      "55it [14:32, 15.96s/it]\u001b[A\n",
      "56it [14:47, 15.84s/it]\u001b[A\n",
      "57it [15:03, 15.78s/it]\u001b[A\n",
      "58it [15:19, 15.75s/it]\u001b[A\n",
      "59it [15:34, 15.73s/it]\u001b[A\n",
      "60it [15:50, 15.72s/it]\u001b[A\n",
      "61it [16:06, 15.71s/it]\u001b[A\n",
      "62it [16:21, 15.69s/it]\u001b[A\n",
      "63it [16:37, 15.68s/it]\u001b[A\n",
      "64it [16:53, 15.65s/it]\u001b[A\n",
      "65it [17:09, 15.69s/it]\u001b[A\n",
      "66it [17:24, 15.68s/it]\u001b[A\n",
      "67it [17:40, 15.70s/it]\u001b[A\n",
      "68it [17:56, 15.72s/it]\u001b[A\n",
      "69it [18:11, 15.69s/it]\u001b[A\n",
      "70it [18:27, 15.69s/it]\u001b[A\n",
      "71it [18:43, 15.71s/it]\u001b[A\n",
      "72it [18:58, 15.71s/it]\u001b[A\n",
      "73it [19:14, 15.75s/it]\u001b[A\n",
      "74it [19:30, 15.80s/it]\u001b[A\n",
      "75it [19:46, 15.81s/it]\u001b[A\n",
      "76it [20:02, 15.85s/it]\u001b[A\n",
      "77it [20:18, 15.85s/it]\u001b[A\n",
      "78it [20:34, 15.87s/it]\u001b[A\n",
      "79it [20:50, 15.85s/it]\u001b[A\n",
      "80it [21:05, 15.85s/it]\u001b[A\n",
      "81it [21:23, 16.47s/it]\u001b[A\n",
      "82it [21:39, 16.20s/it]\u001b[A\n",
      "83it [21:55, 16.05s/it]\u001b[A\n",
      "84it [22:10, 15.93s/it]\u001b[A\n",
      "85it [22:26, 15.85s/it]\u001b[A\n",
      "86it [22:42, 15.78s/it]\u001b[A\n",
      "87it [22:57, 15.74s/it]\u001b[A\n",
      "88it [23:13, 15.68s/it]\u001b[A\n",
      "89it [23:28, 15.69s/it]\u001b[A\n",
      "90it [23:45, 15.85s/it]\u001b[A\n",
      "91it [24:00, 15.84s/it]\u001b[A\n",
      "92it [24:16, 15.83s/it]\u001b[A\n",
      "93it [24:32, 15.83s/it]\u001b[A\n",
      "94it [24:48, 15.76s/it]\u001b[A\n",
      "95it [25:03, 15.73s/it]\u001b[A\n",
      "96it [25:19, 15.71s/it]\u001b[A\n",
      "97it [25:35, 15.70s/it]\u001b[A\n",
      "98it [25:50, 15.68s/it]\u001b[A\n",
      "99it [26:06, 15.69s/it]\u001b[A\n",
      "100it [26:22, 15.67s/it]\u001b[A\n",
      "101it [26:37, 15.71s/it]\u001b[A\n",
      "102it [26:53, 15.71s/it]\u001b[A\n",
      "103it [27:09, 15.75s/it]\u001b[A\n",
      "104it [27:25, 15.73s/it]\u001b[A\n",
      "105it [27:40, 15.72s/it]\u001b[A\n",
      "106it [27:56, 15.72s/it]\u001b[A\n",
      "107it [28:12, 15.71s/it]\u001b[A\n",
      "108it [28:27, 15.70s/it]\u001b[A\n",
      "109it [28:43, 15.65s/it]\u001b[A\n",
      "110it [28:59, 15.67s/it]\u001b[A\n",
      "111it [29:14, 15.63s/it]\u001b[A\n",
      "112it [29:30, 15.71s/it]\u001b[A\n",
      "113it [29:46, 15.69s/it]\u001b[A\n",
      "114it [30:01, 15.66s/it]\u001b[A\n",
      "115it [30:17, 15.64s/it]\u001b[A\n",
      "116it [30:33, 15.64s/it]\u001b[A\n",
      "117it [30:48, 15.63s/it]\u001b[A\n",
      "118it [31:04, 15.64s/it]\u001b[A\n",
      "119it [31:19, 15.58s/it]\u001b[A\n",
      "120it [31:37, 16.23s/it]\u001b[A\n",
      "121it [31:53, 15.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****epoch: 4 loss: 2.701****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [2:07:53<31:57, 1917.51s/it]  \n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:17, 17.48s/it]\u001b[A\n",
      "2it [00:33, 16.93s/it]\u001b[A\n",
      "3it [00:48, 16.53s/it]\u001b[A\n",
      "4it [01:04, 16.43s/it]\u001b[A\n",
      "5it [01:20, 16.18s/it]\u001b[A\n",
      "6it [01:36, 16.01s/it]\u001b[A\n",
      "7it [01:51, 15.88s/it]\u001b[A\n",
      "8it [02:07, 15.83s/it]\u001b[A\n",
      "9it [02:22, 15.75s/it]\u001b[A\n",
      "10it [02:38, 15.70s/it]\u001b[A\n",
      "11it [02:54, 15.72s/it]\u001b[A\n",
      "12it [03:10, 15.72s/it]\u001b[A\n",
      "13it [03:25, 15.67s/it]\u001b[A\n",
      "14it [03:41, 15.67s/it]\u001b[A\n",
      "15it [03:57, 15.69s/it]\u001b[A\n",
      "16it [04:12, 15.71s/it]\u001b[A\n",
      "17it [04:28, 15.70s/it]\u001b[A\n",
      "18it [04:44, 15.71s/it]\u001b[A\n",
      "19it [04:59, 15.72s/it]\u001b[A\n",
      "20it [05:15, 15.69s/it]\u001b[A\n",
      "21it [05:31, 15.71s/it]\u001b[A\n",
      "22it [05:46, 15.71s/it]\u001b[A\n",
      "23it [06:02, 15.77s/it]\u001b[A\n",
      "24it [06:18, 15.83s/it]\u001b[A\n",
      "25it [06:35, 15.96s/it]\u001b[A\n",
      "26it [06:51, 16.18s/it]\u001b[A\n",
      "27it [07:09, 16.50s/it]\u001b[A\n",
      "28it [07:25, 16.51s/it]\u001b[A\n",
      "29it [07:42, 16.54s/it]\u001b[A\n",
      "30it [07:58, 16.56s/it]\u001b[A\n",
      "31it [08:15, 16.60s/it]\u001b[A\n",
      "32it [08:32, 16.61s/it]\u001b[A\n",
      "33it [08:48, 16.58s/it]\u001b[A\n",
      "34it [09:05, 16.62s/it]\u001b[A\n",
      "35it [09:21, 16.58s/it]\u001b[A\n",
      "36it [09:40, 17.15s/it]\u001b[A\n",
      "37it [09:57, 17.06s/it]\u001b[A\n",
      "38it [10:13, 16.95s/it]\u001b[A\n",
      "39it [10:30, 16.86s/it]\u001b[A\n",
      "40it [10:47, 16.76s/it]\u001b[A\n",
      "41it [11:03, 16.73s/it]\u001b[A\n",
      "42it [11:20, 16.67s/it]\u001b[A\n",
      "43it [11:36, 16.57s/it]\u001b[A\n",
      "44it [11:52, 16.35s/it]\u001b[A\n",
      "45it [12:08, 16.20s/it]\u001b[A\n",
      "46it [12:24, 16.08s/it]\u001b[A\n",
      "47it [12:39, 16.02s/it]\u001b[A\n",
      "48it [12:55, 15.97s/it]\u001b[A\n",
      "49it [13:11, 16.01s/it]\u001b[A\n",
      "50it [13:27, 15.95s/it]\u001b[A\n",
      "51it [13:43, 15.92s/it]\u001b[A\n",
      "52it [13:59, 15.94s/it]\u001b[A\n",
      "53it [14:15, 15.90s/it]\u001b[A\n",
      "54it [14:31, 15.88s/it]\u001b[A\n",
      "55it [14:46, 15.83s/it]\u001b[A\n",
      "56it [15:02, 15.83s/it]\u001b[A\n",
      "57it [15:18, 15.77s/it]\u001b[A\n",
      "58it [15:34, 15.73s/it]\u001b[A\n",
      "59it [15:49, 15.69s/it]\u001b[A\n",
      "60it [16:05, 15.71s/it]\u001b[A\n",
      "61it [16:21, 15.69s/it]\u001b[A\n",
      "62it [16:36, 15.67s/it]\u001b[A\n",
      "63it [16:52, 15.68s/it]\u001b[A\n",
      "64it [17:07, 15.67s/it]\u001b[A\n",
      "65it [17:23, 15.67s/it]\u001b[A\n",
      "66it [17:39, 15.70s/it]\u001b[A\n",
      "67it [17:55, 15.73s/it]\u001b[A\n",
      "68it [18:10, 15.74s/it]\u001b[A\n",
      "69it [18:26, 15.78s/it]\u001b[A\n",
      "70it [18:42, 15.77s/it]\u001b[A\n",
      "71it [18:58, 15.75s/it]\u001b[A\n",
      "72it [19:14, 15.78s/it]\u001b[A\n",
      "73it [19:29, 15.78s/it]\u001b[A\n",
      "74it [19:45, 15.78s/it]\u001b[A\n",
      "75it [20:03, 16.44s/it]\u001b[A\n",
      "76it [20:19, 16.26s/it]\u001b[A\n",
      "77it [20:35, 16.12s/it]\u001b[A\n",
      "78it [20:51, 16.00s/it]\u001b[A\n",
      "79it [21:06, 15.97s/it]\u001b[A\n",
      "80it [21:22, 15.88s/it]\u001b[A\n",
      "81it [21:38, 15.82s/it]\u001b[A\n",
      "82it [21:53, 15.75s/it]\u001b[A\n",
      "83it [22:09, 15.74s/it]\u001b[A\n",
      "84it [22:26, 16.11s/it]\u001b[A\n",
      "85it [22:42, 15.96s/it]\u001b[A\n",
      "86it [22:57, 15.88s/it]\u001b[A\n",
      "87it [23:13, 15.81s/it]\u001b[A\n",
      "88it [23:29, 15.81s/it]\u001b[A\n",
      "89it [23:45, 15.78s/it]\u001b[A\n",
      "90it [24:00, 15.76s/it]\u001b[A\n",
      "91it [24:16, 15.77s/it]\u001b[A\n",
      "92it [24:32, 15.76s/it]\u001b[A\n",
      "93it [24:47, 15.73s/it]\u001b[A\n",
      "94it [25:03, 15.71s/it]\u001b[A\n",
      "95it [25:19, 15.67s/it]\u001b[A\n",
      "96it [25:34, 15.67s/it]\u001b[A\n",
      "97it [25:50, 15.62s/it]\u001b[A\n",
      "98it [26:06, 15.65s/it]\u001b[A\n",
      "99it [26:21, 15.69s/it]\u001b[A\n",
      "100it [26:37, 15.74s/it]\u001b[A\n",
      "101it [26:53, 15.78s/it]\u001b[A\n",
      "102it [27:09, 15.79s/it]\u001b[A\n",
      "103it [27:25, 15.78s/it]\u001b[A\n",
      "104it [27:40, 15.76s/it]\u001b[A\n",
      "105it [27:56, 15.72s/it]\u001b[A\n",
      "106it [28:12, 15.73s/it]\u001b[A\n",
      "107it [28:27, 15.73s/it]\u001b[A\n",
      "108it [28:43, 15.75s/it]\u001b[A\n",
      "109it [28:59, 15.75s/it]\u001b[A\n",
      "110it [29:15, 15.71s/it]\u001b[A\n",
      "111it [29:30, 15.75s/it]\u001b[A\n",
      "112it [29:46, 15.70s/it]\u001b[A\n",
      "113it [30:04, 16.39s/it]\u001b[A\n",
      "114it [30:20, 16.17s/it]\u001b[A\n",
      "115it [30:35, 15.99s/it]\u001b[A\n",
      "116it [30:51, 15.82s/it]\u001b[A\n",
      "117it [31:06, 15.76s/it]\u001b[A\n",
      "118it [31:22, 15.68s/it]\u001b[A\n",
      "119it [31:37, 15.63s/it]\u001b[A\n",
      "120it [31:53, 15.58s/it]\u001b[A\n",
      "121it [32:08, 15.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****epoch: 5 loss: 2.544****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [2:40:03<00:00, 1920.79s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>temperature</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>output_dim</th>\n",
       "      <th>rotation</th>\n",
       "      <th>shift</th>\n",
       "      <th>flip</th>\n",
       "      <th>zoom</th>\n",
       "      <th>jitter</th>\n",
       "      <th>blur</th>\n",
       "      <th>best_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.573758</td>\n",
       "      <td>0.1</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.097945</td>\n",
       "      <td>0.1</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.886214</td>\n",
       "      <td>0.1</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.700789</td>\n",
       "      <td>0.1</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.543520</td>\n",
       "      <td>0.1</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  temperature  batch_size  epochs  ...  zoom  jitter  blur  best_epoch\n",
       "0  3.573758          0.1          32       5  ...   180     180   180           5\n",
       "1  3.097945          0.1          32       5  ...   180     180   180           5\n",
       "2  2.886214          0.1          32       5  ...   180     180   180           5\n",
       "3  2.700789          0.1          32       5  ...   180     180   180           5\n",
       "4  2.543520          0.1          32       5  ...   180     180   180           5\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model('simclr1',\n",
    "          BATCH_SIZE=32,\n",
    "          epochs=5,\n",
    "          architecture=ResNet50,\n",
    "          temperature=0.1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-DrpfQvyJbN9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "simclr_data_augmentaion",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
